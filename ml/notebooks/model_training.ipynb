{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d9a4b7b",
   "metadata": {},
   "source": [
    "# Load data from database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129ffbaf",
   "metadata": {},
   "source": [
    "### create session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43a274e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Spark Session crÃ©Ã©e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "jdbc_path = \"/mnt/c/Users/user/Desktop/Quant-AI-Project/postgresql-42.7.1.jar\"\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETA_Model_Training\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.jars\", jdbc_path) \\\n",
    "    .getOrCreate()\n",
    "print(\"âœ… Spark Session crÃ©Ã©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95ba092",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2bd296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Chargement des donnÃ©es Silver...\n",
      "âœ… 589 lignes chargÃ©es\n",
      "ðŸ“Š Colonnes disponibles: ['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_volume', 'taker_buy_quote_volume', 'close_t_plus_10', 'return', 'MA_5', 'MA_10', 'taker_ratio']\n",
      "+-------------------+--------+--------+--------+--------+--------+--------------------+------------------+----------------+---------------------+----------------------+---------------+--------------------+-----------------+-----------------+-------------------+\n",
      "|          open_time|    open|    high|     low|   close|  volume|          close_time|quote_asset_volume|number_of_trades|taker_buy_base_volume|taker_buy_quote_volume|close_t_plus_10|              return|             MA_5|            MA_10|        taker_ratio|\n",
      "+-------------------+--------+--------+--------+--------+--------+--------------------+------------------+----------------+---------------------+----------------------+---------------+--------------------+-----------------+-----------------+-------------------+\n",
      "|2026-01-19 12:45:00|93159.02| 93172.0|93138.57| 93172.0| 8.92988|2026-01-19 12:45:...|    831779.0943744|            2330|              4.95472|        461507.3373702|       93057.17|1.392242920520014...|        93182.796|         93187.11| 0.5548473215765497|\n",
      "|2026-01-19 13:11:00|93018.56|93018.57| 93000.0|93015.86| 3.33202|2026-01-19 13:11:...|    309912.0077839|            1345|              2.19482|        204142.3225021|        92918.1|-2.90264652559348...|93012.74399999999|93003.74600000001| 0.6587055299788116|\n",
      "|2026-01-19 11:24:00| 93114.8|93119.99|93114.79|93119.98| 5.75755|2026-01-19 11:24:...|    536123.4944769|             590|              3.54774|        330350.9730797|       93112.04|5.573765456596453E-5|        93087.578|        93070.899| 0.6161891776884265|\n",
      "|2026-01-19 13:41:00| 93139.2| 93139.2|93109.12|93115.37| 5.93696|2026-01-19 13:41:...|    552877.7353403|            2212|              3.01888|        281124.9213325|       93039.15|-2.55960942765254...|        93077.744|        93047.026|  0.508489193122406|\n",
      "|2026-01-19 08:29:00|93086.36|93086.36|92974.99|92974.99|19.70766|2026-01-19 08:29:...|    1833329.748616|            2162|              1.05393|         98031.6162787|        93074.1|-0.00119641588735...|93087.44999999998|93106.73300000001|0.05347819071366159|\n",
      "+-------------------+--------+--------+--------+--------+--------+--------------------+------------------+----------------+---------------------+----------------------+---------------+--------------------+-----------------+-----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- open_time: timestamp (nullable = true)\n",
      " |-- open: double (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- close: double (nullable = true)\n",
      " |-- volume: double (nullable = true)\n",
      " |-- close_time: timestamp (nullable = true)\n",
      " |-- quote_asset_volume: double (nullable = true)\n",
      " |-- number_of_trades: long (nullable = true)\n",
      " |-- taker_buy_base_volume: double (nullable = true)\n",
      " |-- taker_buy_quote_volume: double (nullable = true)\n",
      " |-- close_t_plus_10: double (nullable = true)\n",
      " |-- return: double (nullable = true)\n",
      " |-- MA_5: double (nullable = true)\n",
      " |-- MA_10: double (nullable = true)\n",
      " |-- taker_ratio: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://localhost:5433/{os.getenv('DATABASE_NAME')}\"\n",
    "connection_properties = {\n",
    "    \"user\": os.getenv('DATABASE_USER'),\n",
    "    \"password\": os.getenv('DATABASE_PASSWORD'),\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "print(\"ðŸ“¥ Chargement des donnÃ©es Silver...\")\n",
    "df = spark.read.jdbc(\n",
    "    url=jdbc_url,\n",
    "    table=\"silver_table\",\n",
    "    properties=connection_properties\n",
    ")\n",
    "\n",
    "print(f\"âœ… {df.count()} lignes chargÃ©es\")\n",
    "print(f\"ðŸ“Š Colonnes disponibles: {df.columns}\")\n",
    "\n",
    "# Afficher un aperÃ§u\n",
    "df.show(5)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883f01a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total clean rows: 589\n",
      "Train samples: 471 (80.0%)\n",
      "Test samples: 118 (20.0%)\n",
      "Pipeline stages:\n",
      "  1. VectorAssembler - Combine features\n",
      "  2. StandardScaler - Scale features\n",
      "  3. RandomForestRegressor - Train model\n",
      "\n",
      "======================================================================\n",
      " TRAINING SET METRICS\n",
      "======================================================================\n",
      "  RMSE: $80.61\n",
      "  MAE:  $61.72\n",
      "  RÂ²:   0.884222\n",
      "  MAPE: 0.07%\n",
      "\n",
      "======================================================================\n",
      " TEST SET METRICS (MOST IMPORTANT)\n",
      "======================================================================\n",
      "  RMSE: $84.04\n",
      "  MAE:  $69.44\n",
      "  RÂ²:   0.196408\n",
      "  MAPE: 0.07%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, abs as spark_abs, mean\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "total_rows = df.count()\n",
    "\n",
    "# STEP 1: DEFINE FEATURES\n",
    "feature_cols = [\n",
    "    'open', 'high', 'low', 'close',              \n",
    "    'volume', 'quote_asset_volume',               \n",
    "    'number_of_trades',                           \n",
    "    'taker_buy_base_volume', \n",
    "    'taker_buy_quote_volume',  \n",
    "    'return',                                    \n",
    "    'MA_5', \n",
    "    'MA_10',                             \n",
    "    'taker_ratio'\n",
    "]\n",
    "\n",
    "target_col = 'close_t_plus_10'\n",
    "\n",
    "\n",
    "# Calculate split point (80% train, 20% test)\n",
    "train_size = int(total_rows * 0.8)\n",
    "\n",
    "# Get train data (first 80% chronologically)\n",
    "train_df = df.orderBy(\"open_time\").limit(train_size)\n",
    "\n",
    "# Get test data (last 20% chronologically)\n",
    "test_df = df.orderBy(\"open_time\").subtract(train_df)\n",
    "\n",
    "# Verify split\n",
    "train_count = train_df.count()\n",
    "test_count = test_df.count()\n",
    "\n",
    "print(f\"Train samples: {train_count} ({train_count/total_rows*100:.1f}%)\")\n",
    "print(f\"Test samples: {test_count} ({test_count/total_rows*100:.1f}%)\")\n",
    "\n",
    "# Drop time columns after split (keep only features and target)\n",
    "train_df = train_df.drop(\"open_time\", \"close_time\")\n",
    "test_df = test_df.drop(\"open_time\", \"close_time\")\n",
    "\n",
    "# Assemble features into vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features_raw\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "# Scale features (helps with large Bitcoin price values)\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_raw\",\n",
    "    outputCol=\"features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "lr_model = LinearRegression(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=target_col,\n",
    "    maxIter=100,\n",
    "    regParam=0.1,              # Ridge regularization\n",
    "    elasticNetParam=0.0,       # Pure Ridge (L2)\n",
    "    standardization=False      # Already scaled\n",
    ")\n",
    "\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    assembler,\n",
    "    scaler,\n",
    "    lr_model\n",
    "])\n",
    "# STEP 2: TRAIN MODEL\n",
    "model = pipeline.fit(train_df)\n",
    "# \n",
    "# STEP 3: MAKE PREDICTIONS\n",
    "train_pred = model.transform(train_df)\n",
    "test_pred = model.transform(test_df)\n",
    "\n",
    "# STEP 4: EVALUATE MODEL\n",
    "\n",
    "# Define evaluators\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=target_col,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol=target_col,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\"\n",
    ")\n",
    "\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=target_col,\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "# Calculate metrics for TRAIN set\n",
    "train_rmse = rmse_evaluator.evaluate(train_pred)\n",
    "train_mae = mae_evaluator.evaluate(train_pred)\n",
    "train_r2 = r2_evaluator.evaluate(train_pred)\n",
    "\n",
    "# Calculate metrics for TEST set\n",
    "test_rmse = rmse_evaluator.evaluate(test_pred)\n",
    "test_mae = mae_evaluator.evaluate(test_pred)\n",
    "test_r2 = r2_evaluator.evaluate(test_pred)\n",
    "\n",
    "# Calculate MAPE (Mean Absolute Percentage Error) - Important for Bitcoin!\n",
    "train_mape_df = train_pred.withColumn(\n",
    "    \"percentage_error\", \n",
    "    spark_abs((col(target_col) - col(\"prediction\")) / col(target_col)) * 100\n",
    ")\n",
    "train_mape = train_mape_df.select(mean(\"percentage_error\")).first()[0]\n",
    "\n",
    "test_mape_df = test_pred.withColumn(\n",
    "    \"percentage_error\", \n",
    "    spark_abs((col(target_col) - col(\"prediction\")) / col(target_col)) * 100\n",
    ")\n",
    "test_mape = test_mape_df.select(mean(\"percentage_error\")).first()[0]\n",
    "\n",
    "# DISPLAY RESULTS\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" TRAINING SET METRICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  RMSE: ${train_rmse:,.2f}\")\n",
    "print(f\"  MAE:  ${train_mae:,.2f}\")\n",
    "print(f\"  RÂ²:   {train_r2:.6f}\")\n",
    "print(f\"  MAPE: {train_mape:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" TEST SET METRICS (MOST IMPORTANT)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  RMSE: ${test_rmse:,.2f}\")\n",
    "print(f\"  MAE:  ${test_mae:,.2f}\")\n",
    "print(f\"  RÂ²:   {test_r2:.6f}\")\n",
    "print(f\"  MAPE: {test_mape:.2f}%\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b95caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Saving model to: /mnt/c/Users/user/Desktop/Quant-AI-Project/ml/models/btc_price_predictor\n",
      "âœ… Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/mnt/c/Users/user/Desktop/Quant-AI-Project/ml/models/btc_price_predictor\"\n",
    "print(f\"\\nðŸ’¾ Saving model to: {model_path}\")\n",
    "\n",
    "model.write().overwrite().save(model_path)\n",
    "print(\"âœ… Model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
